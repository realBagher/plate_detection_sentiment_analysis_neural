{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-24T06:30:03.637233Z",
     "start_time": "2025-02-24T06:29:50.897130Z"
    }
   },
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import DetrFeatureExtractor, DetrForObjectDetection, TrainingArguments, Trainer\n",
    "\n",
    "# Define a dataset for car images (scene images) using XML annotations.\n",
    "class CarImageDetectionDataset(Dataset):\n",
    "    def __init__(self, image_dir, annotation_dir, transforms=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.annotation_dir = annotation_dir\n",
    "        self.transforms = transforms\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_file = self.image_files[idx]\n",
    "        image_path = os.path.join(self.image_dir, image_file)\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # Look for the corresponding XML file (assumes same base name)\n",
    "        annotation_path = os.path.join(self.annotation_dir, os.path.splitext(image_file)[0] + \".xml\")\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        try:\n",
    "            tree = ET.parse(annotation_path)\n",
    "            root = tree.getroot()\n",
    "            # Iterate over all annotated objects in the XML.\n",
    "            for obj in root.findall(\"object\"):\n",
    "                name = obj.find(\"name\").text\n",
    "                # Use only the full plate region label.\n",
    "                if name.strip() == \"کل ناحیه پلاک\":\n",
    "                    bndbox = obj.find(\"bndbox\")\n",
    "                    xmin = float(bndbox.find(\"xmin\").text)\n",
    "                    ymin = float(bndbox.find(\"ymin\").text)\n",
    "                    xmax = float(bndbox.find(\"xmax\").text)\n",
    "                    ymax = float(bndbox.find(\"ymax\").text)\n",
    "                    boxes.append([xmin, ymin, xmax, ymax])\n",
    "                    # Our single class (\"license plate\") gets index 1.\n",
    "                    labels.append(1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing {annotation_path}: {e}\")\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        target[\"class_labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        target[\"image_id\"] = torch.tensor([idx])\n",
    "        return image, target\n",
    "\n",
    "# Paths to your test (or validation) car images and their XML files.\n",
    "train_image_dir = \"/content/car_image_test/test\"         # Or use the validation folder\n",
    "train_annotation_dir = \"/content/car_image_test/test\"      # Assuming XML files are in the same folder\n",
    "\n",
    "# Create the dataset\n",
    "train_dataset = CarImageDetectionDataset(train_image_dir, train_annotation_dir)\n",
    "\n",
    "# Load the pre-trained DETR and its feature extractor.\n",
    "print(\"Loading DETR and feature extractor...\")\n",
    "feature_extractor = DetrFeatureExtractor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "# Modify the model head to support one object class (license plate).\n",
    "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\", num_labels=2, ignore_mismatched_sizes=True)\n",
    "model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define a collate function that uses the feature extractor.\n",
    "def collate_fn(batch):\n",
    "    images, targets = list(zip(*batch))\n",
    "    encoding = feature_extractor(images=list(images), return_tensors=\"pt\")\n",
    "    # We pass the targets (list of dicts) along with the pixel_values.\n",
    "    encoding[\"labels\"] = targets\n",
    "    return encoding\n",
    "\n",
    "# Define training arguments.\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./detr-finetuned\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=2,\n",
    "    evaluation_strategy=\"no\",  # For simplicity, we do only training here.\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    save_steps=500,\n",
    "    warmup_steps=100,\n",
    ")\n",
    "\n",
    "# Create the Trainer.\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=collate_fn,\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.virtualenvs/ai/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-02-24 09:59:58.266143: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740378598.378014     773 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740378598.409177     773 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-24 09:59:58.682438: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/car_image_test/test'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 59\u001B[0m\n\u001B[1;32m     56\u001B[0m train_annotation_dir \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/content/car_image_test/test\u001B[39m\u001B[38;5;124m\"\u001B[39m      \u001B[38;5;66;03m# Assuming XML files are in the same folder\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;66;03m# Create the dataset\u001B[39;00m\n\u001B[0;32m---> 59\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mCarImageDetectionDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_image_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_annotation_dir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;66;03m# Load the pre-trained DETR and its feature extractor.\u001B[39;00m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoading DETR and feature extractor...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[1], line 15\u001B[0m, in \u001B[0;36mCarImageDetectionDataset.__init__\u001B[0;34m(self, image_dir, annotation_dir, transforms)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mannotation_dir \u001B[38;5;241m=\u001B[39m annotation_dir\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms \u001B[38;5;241m=\u001B[39m transforms\n\u001B[0;32m---> 15\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimage_files \u001B[38;5;241m=\u001B[39m [f \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlistdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_dir\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m f\u001B[38;5;241m.\u001B[39mlower()\u001B[38;5;241m.\u001B[39mendswith((\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.jpg\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.jpeg\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.png\u001B[39m\u001B[38;5;124m'\u001B[39m))]\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/content/car_image_test/test'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Start fine-tuning.\n",
    "print(\"Starting DETR fine-tuning...\")\n",
    "trainer.train()"
   ],
   "id": "824790297e84e5c4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
